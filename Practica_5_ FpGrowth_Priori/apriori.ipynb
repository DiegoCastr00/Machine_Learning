{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I1': 4, 'I2': 5, 'I3': 4, 'I4': 4, 'I5': 2}\n",
      "***************************************\n",
      "Frecuencia 1-itemset  ['I1', 'I2', 'I3', 'I4']\n",
      "***************************************\n",
      "------------------------------------\n",
      "Frecuencia 2 -itemset  ['12I', '13I', '23I', '24I']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "def Apriori_gen(Itemset, tamano):\n",
    "    \"\"\"Too generate new (k+1)-itemsets can see README Join Stage\"\"\"\n",
    "    canditato = []\n",
    "    indice_canditato = 0\n",
    "    for i in range (0,tamano):\n",
    "        element = str(Itemset[i])\n",
    "        for j in range (i+1,tamano):\n",
    "            element1 = str(Itemset[j])\n",
    "            if element[0:(len(element)-1)] == element1[0:(len(element1)-1)]:\n",
    "                    unionset = element[0:(len(element)-1)]+element1[len(element1)-1]+element[len(element)-1] #Combinar (k-1)-Itemset con k-Itemset\n",
    "                    unionset = ''.join(sorted(unionset))  #ordenar itemset con dict order\n",
    "                    canditato.append(unionset)\n",
    "    return canditato\n",
    "\n",
    "def Apriori_prune(Ck,MinSoport):\n",
    "    L = []\n",
    "    for i in Ck:\n",
    "        if Ck[i] >= minsoport:\n",
    "            L.append(i)\n",
    "    return sorted(L)\n",
    "def Apriori_conteo_subset(Candidato,Candidato_tamano):\n",
    "\n",
    "    Lk = dict()\n",
    "    archivo = open('datos3.txt')\n",
    "    for l in archivo:\n",
    "        l = str(l.split())\n",
    "        conteo = 0\n",
    "        for i in range (0,Candidato_tamano):\n",
    "            habilitar = str(Candidato[i])\n",
    "            if habilitar not in Lk:\n",
    "                Lk[habilitar] = 0\n",
    "            bandera = True\n",
    "            for k in habilitar:\n",
    "                if k not in l:\n",
    "                    bandera = False\n",
    "            if bandera:\n",
    "                Lk[habilitar] += 1\n",
    "    archivo.close()\n",
    "    return Lk\n",
    "\n",
    "C1={}\n",
    "archivo = open('datos3.txt')\n",
    "\n",
    "for linea in archivo:\n",
    "    for item in linea.split():\n",
    "        if item in C1:\n",
    "            C1[item] +=1\n",
    "        else:\n",
    "            C1[item] = 1\n",
    "archivo.close()\n",
    "print(C1)\n",
    "L = []\n",
    "\n",
    "minsoport = 3\n",
    "\n",
    "L1 = Apriori_prune(C1,minsoport)\n",
    "L = Apriori_gen(L1,len(L1))\n",
    "print ('***************************************')\n",
    "print ('Frecuencia 1-itemset ',L1)\n",
    "print ('***************************************')\n",
    "k=2\n",
    "while L != []:\n",
    "    C = dict()\n",
    "    C = Apriori_conteo_subset(L,len(L))\n",
    "    frecuencia_itemset = []\n",
    "    frecuencia_itemset = Apriori_prune(C,minsoport)\n",
    "    print ('------------------------------------')\n",
    "    print ('Frecuencia',k,'-itemset ',frecuencia_itemset)\n",
    "    #print ('------------------------------------')\n",
    "    L = Apriori_gen(frecuencia_itemset,len(frecuencia_itemset))\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mínimo conteo de soporte:\n",
      "3\n",
      "Todas las frecuencias de los itemsets:\n",
      "[{'I3'}, {'I3', 'I2'}, {'I1'}, {'I3', 'I1'}, {'I3', 'I2', 'I1'}, {'I2', 'I1'}, {'I4'}, {'I4', 'I2'}, {'I2'}]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"FPgrowth_reglas_asoc.ipynb\"\"\"\n",
    "\n",
    "\n",
    "#Función para cargar archivos y devolver listas de transacciones\n",
    "def cargar_datos(archivo):\n",
    "    with open(archivo) as f:\n",
    "        contenido = f.readlines()\n",
    "\n",
    "    contenido = [x.strip() for x in contenido]\n",
    "    Transaccion = []\n",
    "\n",
    "    for i in range(0, len(contenido)):\n",
    "        Transaccion.append(contenido[i].split())\n",
    "\n",
    "    return Transaccion\n",
    "\n",
    "#Para convertir la transacción inicial y mantenerla frozenset\n",
    "def Set_inicio(dataset):\n",
    "    retDict = {}\n",
    "    for trans in dataset:\n",
    "        retDict[frozenset(trans)] = 1\n",
    "    return retDict\n",
    "\n",
    "#clase de nodo arbol FP\n",
    "class nodos_arbol:\n",
    "    def __init__(self, Nodo,conteo,nodoPadre):\n",
    "        self.nodoC = Nodo\n",
    "        self.count = conteo\n",
    "        self.nodoLiga = None\n",
    "        self.padre = nodoPadre\n",
    "        self.hijo = {}\n",
    "\n",
    "    def incremento_contador(self, contador):\n",
    "        self.count += contador\n",
    "\n",
    "#Para crear Raiz_arbol y itemsets ordenados para arbol FP\n",
    "def crear_FP_Arbol(dataset, minSoport):\n",
    "    Raiz_arbol = {}\n",
    "    for transaccion in dataset:\n",
    "        for item in transaccion:\n",
    "            Raiz_arbol[item] = Raiz_arbol.get(item,0) + dataset[transaccion]\n",
    "    for k in list(Raiz_arbol):\n",
    "        if Raiz_arbol[k] < minSoport:\n",
    "            del(Raiz_arbol[k])\n",
    "\n",
    "    frecuent_itemset = set(Raiz_arbol.keys())\n",
    "\n",
    "    if len(frecuent_itemset) == 0:\n",
    "        return None, None\n",
    "\n",
    "    for k in Raiz_arbol:\n",
    "        Raiz_arbol[k] = [Raiz_arbol[k], None]\n",
    "\n",
    "    retTree = nodos_arbol('Null Set',1,None)\n",
    "    for itemset,contar in dataset.items():\n",
    "        frecuen_transaccion = {}\n",
    "        for item in itemset:\n",
    "            if item in frecuent_itemset:\n",
    "                frecuen_transaccion[item] = Raiz_arbol[item][0]\n",
    "        if len(frecuen_transaccion) > 0:\n",
    "            ordenar_itemset = [v[0] for v in sorted(frecuen_transaccion.items(), key=lambda p: p[1], reverse=True)]\n",
    "            #actualizar FPTree\n",
    "            actualizarArbol(ordenar_itemset, retTree, Raiz_arbol, contar)\n",
    "    return retTree, Raiz_arbol\n",
    "\n",
    "def actualizarArbol(itemset, FPTree, Raiz_arbol, count):\n",
    "    if itemset[0] in FPTree.hijo:\n",
    "        FPTree.hijo[itemset[0]].incremento_contador(count)\n",
    "    else:\n",
    "        FPTree.hijo[itemset[0]] = nodos_arbol(itemset[0], count, FPTree)\n",
    "\n",
    "        if Raiz_arbol[itemset[0]][1] == None:\n",
    "            Raiz_arbol[itemset[0]][1] = FPTree.hijo[itemset[0]]\n",
    "        else:\n",
    "            actualizar_nodo(Raiz_arbol[itemset[0]][1], FPTree.hijo[itemset[0]])\n",
    "\n",
    "    if len(itemset) > 1:\n",
    "        actualizarArbol(itemset[1::], FPTree.hijo[itemset[0]], Raiz_arbol, count)\n",
    "\n",
    "\n",
    "def actualizar_nodo(Nodo_test, nodo_objetivo):\n",
    "    while (Nodo_test.nodoLiga != None):\n",
    "        Nodo_test = Nodo_test.nodoLiga\n",
    "\n",
    "    Nodo_test.nodoLiga = nodo_objetivo\n",
    "\n",
    "\n",
    "def FPTree_transversal(nodo_hoja, ruta_opcion):\n",
    " if nodo_hoja.padre != None:\n",
    "    ruta_opcion.append(nodo_hoja.nodoC)\n",
    "    FPTree_transversal(nodo_hoja.padre, ruta_opcion)\n",
    "\n",
    "def encontrar_ruta(basePat, nodos_arbol):\n",
    " patron_cond_base = {}\n",
    "\n",
    " while nodos_arbol != None:\n",
    "    ruta_opcion = []\n",
    "    FPTree_transversal(nodos_arbol, ruta_opcion)\n",
    "    if len(ruta_opcion) > 1:\n",
    "        patron_cond_base[frozenset(ruta_opcion[1:])] = nodos_arbol.count\n",
    "    nodos_arbol = nodos_arbol.nodoLiga\n",
    "\n",
    " return patron_cond_base\n",
    "\n",
    "\n",
    "def Buscar_Tree(FPTree, indicarTabla, minSuport, prefix, frecuent_itemset):\n",
    "    bigL = [v[0] for v in sorted(indicarTabla.items(),key=lambda p: p[1][0])]\n",
    "    for basePat in bigL:\n",
    "        new_frecuentset = prefix.copy()\n",
    "        new_frecuentset.add(basePat)\n",
    "\n",
    "        frecuent_itemset.append(new_frecuentset)\n",
    "\n",
    "        Patron_base_condi = encontrar_ruta(basePat, indicarTabla[basePat][1])\n",
    "\n",
    "        Condicional_FPTree, Cond_cabecera = crear_FP_Arbol(Patron_base_condi,minSuport)\n",
    "\n",
    "        if Cond_cabecera != None:\n",
    "            Buscar_Tree(Condicional_FPTree, Cond_cabecera, minSuport, new_frecuentset, frecuent_itemset)\n",
    "\n",
    "archivo = 'datos3.txt'\n",
    "print(\"Mínimo conteo de soporte:\")\n",
    "soporte_minimo = 3\n",
    "print(soporte_minimo)\n",
    "initSet = Set_inicio(cargar_datos(archivo))\n",
    "FPtree, indicarTabla = crear_FP_Arbol(initSet, soporte_minimo)\n",
    "\n",
    "frecuent_itemset = []\n",
    "\n",
    "Buscar_Tree(FPtree, indicarTabla, soporte_minimo, set([]), frecuent_itemset)\n",
    "\n",
    "print(\"Todas las frecuencias de los itemsets:\")\n",
    "print(frecuent_itemset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
